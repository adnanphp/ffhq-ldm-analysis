\section{Advanced Diversity Analysis Framework}

\subsection{Comprehensive Diversity Assessment System}

The \texttt{ffhq\_advanced\_diversity\_analysis\_fixed\_v2.py} implements a sophisticated analysis framework for evaluating the diversity of generated FFHQ faces across multiple dimensions: style variation, mode coverage, and novelty assessment. This comprehensive system provides quantitative metrics to assess generative model performance beyond simple image quality.

\subsubsection{System Architecture and Initialization}

\begin{lstlisting}[style=pythonstyle, caption={Advanced Diversity Analyzer Class Initialization}, label={lst:diversity_init}]
class AdvancedDiversityAnalyzer:
    def __init__(self, existing_dir=None):
        """Initialize the advanced diversity analyzer"""
        print("ðŸ”¬ ADVANCED DIVERSITY ANALYSIS")
        print("=" * 60)
        
        if existing_dir and os.path.exists(existing_dir):
            self.output_dir = existing_dir
            print(f"ðŸ“ Using existing directory: {self.output_dir}")
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            self.output_dir = f"advanced_diversity_{timestamp}"
            os.makedirs(self.output_dir, exist_ok=True)
            print(f"ðŸ“ Created new directory: {self.output_dir}")
        
        # Create subdirectories
        self.style_dir = os.path.join(self.output_dir, "style_analysis")
        self.coverage_dir = os.path.join(self.output_dir, "coverage_analysis")
        self.novelty_dir = os.path.join(self.output_dir, "novelty_analysis")
        
        for dir_path in [self.style_dir, self.coverage_dir, self.novelty_dir]:
            os.makedirs(dir_path, exist_ok=True)
        
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ðŸ“± Using device: {self.device}")
\end{lstlisting}

\subsection{Three-Dimensional Diversity Assessment}

\subsubsection{1. Style Variation Analysis}

The style variation analysis examines pose, lighting, and expression diversity using computer vision techniques:

\begin{lstlisting}[style=pythonstyle, caption={Style Feature Extraction}, label={lst:style_features}]
def analyze_style_variation(self, faces):
    """Analyze style variation: pose, lighting, and expression diversity"""
    
    style_features = []
    for face in faces:
        img_np = face['image_np']
        
        # 1. Lighting analysis (brightness and contrast)
        brightness = img_np.mean()
        contrast = img_np.std()
        
        # 2. Color temperature (warm vs cool)
        r, g, b = img_np.mean(axis=(0, 1))
        color_temp = r / (g + 1e-8)  # Red-green ratio
        
        # 3. Symmetry analysis (pose estimation)
        gray = np.mean(img_np, axis=2)
        height, width = gray.shape
        
        # Split image into left and right halves
        left_half = gray[:, :width//2]
        right_half = gray[:, width//2:]
        
        # Flip right half for comparison
        right_half_flipped = np.fliplr(right_half)
        
        # Calculate symmetry score
        symmetry_score = 1.0 - np.abs(left_half - right_half_flipped).mean()
        
        # 4. Expression analysis (mouth region)
        mouth_region = img_np[height//2:, width//4:3*width//4, :]
        mouth_brightness = mouth_region.mean()
        
        # Smile detection (simplified)
        smile_score = min(mouth_brightness / 0.5, 1.0)
        
        features = np.array([
            brightness, contrast, color_temp, symmetry_score,
            smile_score, face_aspect_ratio, sharpness
        ])
        style_features.append(features)
\end{lstlisting}

\subsubsection{Style Diversity Metrics Calculation}

\begin{lstlisting}[style=pythonstyle, caption={Style Diversity Metrics}, label={lst:style_metrics}]
def calculate_style_diversity(self, style_features):
    """Calculate style diversity metrics"""
    # Calculate coefficient of variation for each style dimension
    cv_scores = []
    for i in range(style_features.shape[1]):
        feature = style_features[:, i]
        if feature.mean() > 0:
            cv = feature.std() / feature.mean()
        else:
            cv = feature.std()
        cv_scores.append(cv)
    
    # Define which features correspond to which aspects
    lighting_indices = [0, 1, 2]  # brightness, contrast, color_temp
    pose_indices = [3, 5]         # symmetry, aspect_ratio
    expression_indices = [4]       # smile intensity
    
    lighting_diversity = cv_scores[lighting_indices].mean()
    pose_diversity = cv_scores[pose_indices].mean()
    expression_diversity = cv_scores[expression_indices].mean()
    
    # Overall variation score (higher = more diverse)
    variation_score = cv_scores.mean()
    
    return {
        'variation_score': float(variation_score),
        'lighting_diversity': float(lighting_diversity),
        'pose_diversity': float(pose_diversity),
        'expression_diversity': float(expression_diversity),
        'overall_style_score': float(overall_score)
    }
\end{lstlisting}

\subsubsection{2. Mode Coverage Analysis}

Mode coverage evaluates how well the generated distribution covers the real data distribution using precision-recall metrics:

\begin{lstlisting}[style=pythonstyle, caption={Precision-Recall Calculation}, label={lst:precision_recall}]
def calculate_precision_recall_advanced(self, real_features, gen_features, k=3):
    """Calculate advanced precision and recall metrics"""
    from sklearn.neighbors import NearestNeighbors
    
    # Fit k-NN models
    knn_real = NearestNeighbors(n_neighbors=k, metric='euclidean')
    knn_real.fit(real_features)
    
    knn_gen = NearestNeighbors(n_neighbors=k, metric='euclidean')
    knn_gen.fit(gen_features)
    
    # Calculate distances
    distances_gen_to_real, _ = knn_real.kneighbors(gen_features)
    distances_real_to_gen, _ = knn_gen.kneighbors(real_features)
    
    # Calculate manifold boundaries
    real_manifold = np.percentile(distances_real_to_gen[:, -1], 95)
    gen_manifold = np.percentile(distances_gen_to_real[:, -1], 95)
    
    # Precision: fraction of generated samples within real manifold
    precision = np.mean(distances_gen_to_real[:, -1] <= real_manifold)
    
    # Recall: fraction of real samples within generated manifold
    recall = np.mean(distances_real_to_gen[:, -1] <= gen_manifold)
    
    return precision, recall
\end{lstlisting}

\subsubsection{3. Novelty Assessment}

Novelty assessment measures the uniqueness of generated faces and detects potential memorization:

\begin{lstlisting}[style=pythonstyle, caption={Novelty Assessment}, label={lst:novelty_assessment}]
def analyze_novelty_assessment(self, faces, memorization_threshold=0.1):
    """Analyze novelty: percentage of unique, non-memorized generations"""
    
    # Extract features for comparison
    features = []
    for face in faces:
        img_np = face['image_np']
        
        # Color features
        color_features = img_np.mean(axis=(0, 1)).flatten()
        
        # Texture features
        gray = np.mean(img_np, axis=2)
        contrast = gray.std()
        
        # Shape features
        aspect_ratio = img_np.shape[0] / img_np.shape[1]
        
        # Edge features
        sobel_x = ndimage.sobel(gray, axis=0)
        sobel_y = ndimage.sobel(gray, axis=1)
        edge_magnitude = np.hypot(sobel_x, sobel_y)
        
        feature_vector = np.concatenate([
            color_features,
            np.array([contrast, aspect_ratio, edge_magnitude.mean()])
        ])
        features.append(feature_vector)
    
    # Calculate pairwise similarities
    similarity_matrix = self.calculate_similarity_matrix_fixed(features)
    
    # Identify potential memorizations (very similar pairs)
    memorization_mask = similarity_matrix > (1.0 - memorization_threshold)
    np.fill_diagonal(memorization_mask, False)
    
    # Count unique vs potentially memorized
    n_faces = len(faces)
    n_potential_memorizations = np.sum(memorization_mask) // 2
    
    return {
        'total_faces': n_faces,
        'potential_memorizations': int(n_potential_memorizations),
        'unique_faces': int(n_faces - n_potential_memorizations),
        'novelty_percentage': float((n_faces - n_potential_memorizations) / n_faces * 100)
    }
\end{lstlisting}

\subsection{Visualization System}

\subsubsection{Comprehensive Visualizations}

The analysis generates multiple visualization types:

\begin{lstlisting}[style=pythonstyle, caption={Visualization Creation}, label={lst:visualizations}]
def create_style_visualizations(self, style_features, style_metrics, faces, 
                               style_diversity, style_clusters):
    """Create visualizations for style analysis"""
    
    # Create figure with multiple subplots
    fig = plt.figure(figsize=(18, 12))
    
    # 1. Style features radar chart
    ax1 = plt.subplot(2, 3, 1, projection='polar')
    feature_names = ['Brightness', 'Contrast', 'Color Temp', 'Symmetry', 
                    'Smile', 'Aspect Ratio', 'Sharpness']
    
    # 2. Style diversity scores bar chart
    ax2 = plt.subplot(2, 3, 2)
    diversity_categories = ['Variation', 'Lighting', 'Pose', 'Expression', 'Coverage']
    
    # 3. Cluster visualization (PCA reduced)
    ax3 = plt.subplot(2, 3, 3)
    
    # 4. Example faces from each cluster
    ax4 = plt.subplot(2, 3, 4)
    
    # 5. Style distribution histograms
    ax5 = plt.subplot(2, 3, 5)
    
    # 6. Overall style score gauge
    ax6 = plt.subplot(2, 3, 6)
    
    plt.suptitle('FFHQ Generated Faces - Advanced Style Analysis', 
                fontsize=18, fontweight='bold', y=1.02)
    plt.tight_layout()
\end{lstlisting}

\subsection{Terminal Output Structure}

\begin{lstlisting}[style=terminalstyle, caption={Diversity Analysis Terminal Output}]
ðŸ”¬ ADVANCED DIVERSITY ANALYSIS
============================================================
ðŸ“ Using existing directory: advanced_diversity_20240115_143022
ðŸ“± Using device: cuda

============================================================
LOADING EXISTING FACES FOR ANALYSIS
============================================================
ðŸ“‚ Loading faces from: quantitative_eval_20240115_142045
âœ… Found 45 images in: quantitative_eval_20240115_142045/sample_faces
âœ… Successfully loaded 45 faces

============================================================
ANALYZING STYLE VARIATION
============================================================
ðŸ” Extracting style features...
ðŸ“Š Extracted 7 style features from 45 faces
ðŸ” Analyzing style clusters...
ðŸ“Š Found 4 style clusters:
  Cluster 0 (Smiling): 12 faces (26.7%)
  Cluster 1 (Well-lit): 15 faces (33.3%)
  Cluster 2 (High-contrast): 8 faces (17.8%)
  Cluster 3 (Front-facing): 10 faces (22.2%)

ðŸŽ¯ STYLE DIVERSITY RESULTS:
  Style Variation Score: 0.723
  Pose Diversity: 0.642
  Lighting Diversity: 0.718
  Expression Diversity: 0.694
ðŸ“ˆ Overall Style Score: 0.754 (EXCELLENT style diversity)

============================================================
ANALYZING MODE COVERAGE
============================================================
ðŸ” Calculating mode coverage metrics...
ðŸ’¡ Creating simulated real distribution...

ðŸŽ¯ MODE COVERAGE METRICS:
  Precision: 0.834 (quality of generated samples)
  Recall: 0.689 (coverage of real distribution)
  F1 Score: 0.754
  Density: 0.721 (sample quality within manifolds)
  Coverage: 0.683 (sample diversity)

============================================================
ANALYZING NOVELTY ASSESSMENT
============================================================
ðŸ” Calculating novelty metrics...

ðŸŽ¯ NOVELTY METRICS:
  Total faces analyzed: 45
  Potential memorizations: 3
  Unique faces: 42
  Novelty percentage: 93.3%
  Average similarity: 0.421
  Max similarity: 0.987
  Similarity clusters: 6
ðŸ“ˆ Interpretation: EXCELLENT novelty (highly unique generations)

============================================================
COMPREHENSIVE ADVANCED DIVERSITY REPORT
============================================================
ðŸ“‹ ADVANCED DIVERSITY SCORES:
  Style Diversity: 0.754
  Mode Coverage: 0.754
  Novelty: 0.933
  Overall Score: 0.801

ðŸ“ˆ INTERPRETATION:
  EXCELLENT - Highly diverse, well-covered, and novel generations

ðŸ’¡ RECOMMENDATIONS:
  1. Maintain high precision while improving recall
  2. Consider adjusting guidance scale for better diversity

ðŸ“ All results saved in: advanced_diversity_20240115_143022/
âœ… ADVANCED DIVERSITY ANALYSIS COMPLETE!
\end{lstlisting}

\subsection{Metrics and Scoring System}

\subsubsection{Comprehensive Scoring Framework}

\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Metric Category} & \textbf{Sub-metrics} & \textbf{Weight} \\
\hline
Style Diversity & Variation Score, Lighting Diversity, Pose Diversity, Expression Diversity & 30\% \\
Mode Coverage & Precision, Recall, F1 Score, Density, Coverage & 40\% \\
Novelty Assessment & Novelty Percentage, Unique Faces, Similarity Score & 30\% \\
\hline
\end{tabular}
\caption{Diversity Analysis Scoring Framework}
\label{tab:diversity_scoring}
\end{table}

\subsubsection{Output Files Structure}

The analysis produces a comprehensive directory structure:

\begin{verbatim}
advanced_diversity_20240115_143022/
â”œâ”€â”€ style_analysis/
â”‚   â”œâ”€â”€ style_analysis_results.json
â”‚   â”œâ”€â”€ style_analysis_visualization.png
â”‚   â””â”€â”€ style_cluster_examples.png
â”œâ”€â”€ coverage_analysis/
â”‚   â”œâ”€â”€ coverage_analysis_results.json
â”‚   â””â”€â”€ coverage_analysis_visualization.png
â”œâ”€â”€ novelty_analysis/
â”‚   â”œâ”€â”€ novelty_analysis_results.json
â”‚   â”œâ”€â”€ novelty_analysis_visualization.png
â”‚   â””â”€â”€ most_similar_faces.png
â”œâ”€â”€ loaded_faces_summary.json
â”œâ”€â”€ comprehensive_advanced_diversity_report.json
â””â”€â”€ final_advanced_diversity_assessment.png
\end{verbatim}

\subsection{Interpretation Guidelines}

\subsubsection{Score Interpretation Scale}

\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Score Range} & \textbf{Rating} & \textbf{Interpretation} \\
\hline
0.8 - 1.0 & EXCELLENT & Highly diverse, well-covered, novel generations \\
0.6 - 0.8 & GOOD & Good diversity with minor improvements possible \\
0.4 - 0.6 & MODERATE & Some diversity issues present \\
0.0 - 0.4 & LOW & Significant diversity, coverage, or novelty issues \\
\hline
\end{tabular}
\caption{Diversity Score Interpretation}
\label{tab:score_interpretation}
\end{table}

\subsubsection{Key Performance Indicators}

\begin{itemize}
    \item \textbf{Style Diversity > 0.7}: Excellent variation in pose, lighting, expression
    \item \textbf{Precision > 0.8}: High-quality generated samples
    \item \textbf{Recall > 0.6}: Good coverage of real distribution
    \item \textbf{Novelty > 90\%}: High uniqueness, low memorization
    \item \textbf{F1 Score > 0.7}: Good balance of precision and recall
\end{itemize}

\subsection{Analysis Use Cases}

\subsubsection{1. Model Development}
\begin{itemize}
    \item Compare different sampling strategies
    \item Evaluate impact of guidance scale changes
    \item Test different model architectures
    \item Optimize diversity-parameter trade-offs
\end{itemize}

\subsubsection{2. Quality Assurance}
\begin{itemize}
    \item Monitor model degradation over time
    \item Detect mode collapse early
    \item Identify memorization issues
    \item Ensure consistent generation quality
\end{itemize}

\subsubsection{3. Research Validation}
\begin{itemize}
    \item Benchmark against state-of-the-art models
    \item Reproduce research findings
    \item Validate model improvements
    \item Compare different training methodologies
\end{itemize}

\subsection{Technical Implementation Details}

\subsubsection{Feature Extraction Methods}

The analysis employs multiple feature extraction techniques:

\begin{lstlisting}[style=pythonstyle, caption={Multi-Modal Feature Extraction}, label={lst:feature_extraction}]
def extract_comprehensive_features(self, image_np):
    """Extract comprehensive features for analysis"""
    
    # Color features
    color_mean = image_np.mean(axis=(0, 1))
    color_std = image_np.std(axis=(0, 1))
    
    # Texture features
    gray = np.mean(image_np, axis=2)
    sobel_x = ndimage.sobel(gray, axis=0)
    sobel_y = ndimage.sobel(gray, axis=1)
    edge_magnitude = np.hypot(sobel_x, sobel_y)
    
    # Shape features
    aspect_ratio = image_np.shape[0] / image_np.shape[1]
    
    # Symmetry features
    left_half = gray[:, :gray.shape[1]//2]
    right_half = gray[:, gray.shape[1]//2:]
    symmetry = 1.0 - np.abs(left_half - np.fliplr(right_half)).mean()
    
    # Combine all features
    features = np.concatenate([
        color_mean, color_std,
        np.array([edge_magnitude.mean(), edge_magnitude.std()]),
        np.array([aspect_ratio, symmetry])
    ])
    
    return features
\end{lstlisting}

\subsubsection{Statistical Analysis Methods}

\begin{lstlisting}[style=pythonstyle, caption={Statistical Analysis Methods}, label={lst:statistical_methods}]
def calculate_statistical_metrics(self, features):
    """Calculate comprehensive statistical metrics"""
    
    # Central tendency
    mean = np.mean(features, axis=0)
    median = np.median(features, axis=0)
    
    # Dispersion
    std = np.std(features, axis=0)
    cv = std / (mean + 1e-8)  # Coefficient of variation
    
    # Distribution shape
    from scipy import stats
    skewness = stats.skew(features, axis=0)
    kurtosis = stats.kurtosis(features, axis=0)
    
    # Pairwise distances
    distances = pairwise_distances(features, metric='euclidean')
    
    return {
        'mean': mean.tolist(),
        'std': std.tolist(),
        'cv': cv.tolist(),
        'skewness': skewness.tolist(),
        'kurtosis': kurtosis.tolist(),
        'avg_distance': float(distances.mean()),
        'max_distance': float(distances.max())
    }
\end{lstlisting}

\subsection{Limitations and Considerations}

\subsubsection{Technical Limitations}

\begin{itemize}
    \item \textbf{Feature Dimensionality}: Limited to visual features only
    \item \textbf{Reference Distribution}: Uses simulated real distribution
    \item \textbf{Computational Complexity}: O(nÂ²) for similarity calculations
    \item \textbf{Sample Size Requirements}: Minimum 10 samples for reliable analysis
    \item \textbf{Memory Usage}: Large matrices for pairwise comparisons
\end{itemize}

\subsubsection{Practical Considerations}

\begin{itemize}
    \item \textbf{Hardware Requirements}: GPU recommended for feature extraction
    \item \textbf{Runtime}: Complete analysis takes 5-15 minutes for 100 samples
    \item \textbf{Storage}: Multiple visualization files generated
    \item \textbf{Interpretation Skill}: Requires understanding of statistical metrics
    \item \textbf{Baseline Comparison}: Needs reference data for meaningful interpretation
\end{itemize}

\subsection{Expected Results and Outputs}

\subsubsection{Quantitative Metrics Output}

The analysis produces detailed JSON reports with structured metrics:

\begin{verbatim}
{
  "style_diversity": {
    "variation_score": 0.723,
    "lighting_diversity": 0.718,
    "pose_diversity": 0.642,
    "expression_diversity": 0.694,
    "overall_style_score": 0.754
  },
  "mode_coverage": {
    "precision": 0.834,
    "recall": 0.689,
    "f1_score": 0.754,
    "density": 0.721,
    "coverage": 0.683
  },
  "novelty_analysis": {
    "novelty_percentage": 93.3,
    "unique_faces": 42,
    "potential_memorizations": 3
  }
}
\end{verbatim}

\subsubsection{Visual Output Examples}

The analysis generates multiple visualization types:
\begin{itemize}
    \item Radar charts for style feature distributions
    \item Bar charts for metric comparisons
    \item Heatmaps for similarity matrices
    \item Scatter plots for feature space visualization
    \item Gauge charts for overall scores
    \item Example face grids for qualitative assessment
\end{itemize}

This comprehensive diversity analysis framework provides researchers and developers with a robust toolset for evaluating and improving generative model performance across multiple dimensions.
\end{document}
